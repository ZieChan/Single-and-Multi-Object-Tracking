{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bb12a1-0549-4360-8e39-7d84b8f8a359",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1941f929-ffb8-4569-b3ab-394016766f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# part 1:\n",
    "\n",
    "def load_obj_each_frame(data_file):\n",
    "    with open(data_file, 'r') as file:\n",
    "        frame_dict = json.load(file)\n",
    "    return frame_dict\n",
    "\n",
    "def alpha_beta_filter(initial_position, initial_velocity, alpha, beta, observations, dt=1):\n",
    "    estimated_position = initial_position\n",
    "    estimated_velocity = initial_velocity\n",
    "\n",
    "    estimates = []\n",
    "\n",
    "    for observation in observations:\n",
    "        # Prediction step\n",
    "        predicted_position = estimated_position + estimated_velocity * dt\n",
    "        predicted_velocity = estimated_velocity\n",
    "\n",
    "        # Update step (if observation is available)\n",
    "        if observation != [-1, -1]:\n",
    "            residual = observation - predicted_position\n",
    "            estimated_position = predicted_position + alpha * residual\n",
    "            estimated_velocity = predicted_velocity + (beta * residual) / dt\n",
    "        else:\n",
    "            # If observation is missing, use the prediction\n",
    "            estimated_position = predicted_position\n",
    "            estimated_velocity = predicted_velocity\n",
    "\n",
    "        #print(estimated_position)\n",
    "\n",
    "        estimates.append([estimated_position, estimated_velocity])\n",
    "\n",
    "    return estimates\n",
    "\n",
    "def draw_target_object_center(video_file, obj_centers):\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    ok, image = cap.read()\n",
    "\n",
    "    # Initialize Alpha-Beta filter parameters\n",
    "    initial_position = np.array([313, 229])  # Initial guess for position\n",
    "    initial_velocity = np.array([-0.47328952, -0.3911483 ])  # Initial guess for velocity\n",
    "    \n",
    "    alpha = 0.4 #0.85  # Position update factor, Alpha bigger, \n",
    "    beta = 0.0005 #0.005  # Velocity update factor\n",
    "    \n",
    "    filtered_estimates = alpha_beta_filter(initial_position, initial_velocity, alpha, beta, obj_centers)\n",
    "\n",
    "    # Save in JSON file\n",
    "    aa=[x[0] for x in filtered_estimates]\n",
    "    part_1_object_tracking = [[int(round(x)), int(round(y))] for x, y in aa]\n",
    "    output_data = {\"obj\": part_1_object_tracking}\n",
    "    with open('part_1_object_tracking.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(output_data, file, ensure_ascii=False, indent=None)\n",
    "    \n",
    "    print(\"Position were saved as part_1_object_tracking.json\")\n",
    "\n",
    "    vidwrite = cv.VideoWriter(\"part_1_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "\n",
    "\n",
    "    while ok:\n",
    "        if count < len(filtered_estimates):\n",
    "            pos, _ = filtered_estimates[count]\n",
    "            pos_x, pos_y = pos\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        # Resize the image to match coordinates scaling\n",
    "        image = cv.resize(image, (700, 500))\n",
    "        \n",
    "        # Draw the circle at the estimated position\n",
    "        #if pos_x != -1 and pos_y != -1:\n",
    "        #    image = cv.circle(image, (int(pos_x), int(pos_y)), 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw the Line\n",
    "        for i in range(count):\n",
    "            pos, _ = filtered_estimates[i]\n",
    "            pos_x, pos_y = pos\n",
    "            image = cv.circle(image, (int(pos_x), int(pos_y)), 1, (0, 0, 255), 2)\n",
    "        \n",
    "        vidwrite.write(image)\n",
    "        ok, image = cap.read()\n",
    "\n",
    "    \n",
    "\n",
    "    vidwrite.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7fbcf7ce-eadc-4021-90a9-de052629ee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position were saved as part_1_object_tracking.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "frame_dict = load_obj_each_frame(\"object_to_track.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_target_object_center(video_file,frame_dict['obj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5dbcf9-2323-462b-9b89-0692134149b7",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a28db1-5b21-41ef-b3d9-92dea3086382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2:\n",
    "\n",
    "def draw_object(object_dict,image,color = (0, 255, 0), thickness = 2,c_color= \\\n",
    "                (255, 0, 0)):\n",
    "    # draw box\n",
    "    x = object_dict['x_min']\n",
    "    y = object_dict['y_min']\n",
    "    width = object_dict['width']\n",
    "    height = object_dict['height']\n",
    "    image = cv.rectangle(image, (x, y), (x + width, y + height), color, thickness)\n",
    "    return image\n",
    "\n",
    "def draw_objects_in_video(video_file,frame_dict):\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    ok, image = cap.read()\n",
    "    vidwrite = cv.VideoWriter(\"part_2_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    while ok:\n",
    "        ######!!!!#######\n",
    "        image = cv.resize(image, (700, 500)) # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "        ######!!!!#######\n",
    "        obj_list = frame_dict[str(count)]\n",
    "        for obj in obj_list:\n",
    "          image = draw_object(obj,image)\n",
    "        vidwrite.write(image)\n",
    "        count+=1\n",
    "        ok, image = cap.read()\n",
    "    vidwrite.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21220b42-e6ad-46da-9928-029cdbac1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_dict = load_obj_each_frame(\"frame_dict.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_objects_in_video(video_file,frame_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
